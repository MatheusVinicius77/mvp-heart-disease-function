# ðŸ¥ TabM para DiagnÃ³stico de DoenÃ§a CardÃ­aca: ExploraÃ§Ã£o de MLP Eficiente em Dados Tabulares ClÃ­nicos

## ðŸ“‹ Resumo Executivo

Este trabalho explora a aplicaÃ§Ã£o de **TabM** (Tabular Model) no diagnÃ³stico de doenÃ§a cardÃ­aca coronariana usando o dataset Cleveland. Ao contrÃ¡rio do que o nome pode sugerir, TabM nÃ£o Ã© um Transformer, mas sim uma arquitetura baseada em **MLP (Multi-Layer Perceptron)** simples e eficiente, potencializada por **BatchEnsemble**.

**Objetivo Principal**: Investigar a efetividade de TabM em diagnÃ³stico de doenÃ§a cardÃ­aca, explorando como uma arquitetura feedforward simples pode superar modelos complexos baseados em atenÃ§Ã£o.

**Diferencial**: Primeira aplicaÃ§Ã£o de TabM em contexto de diagnÃ³stico cardÃ­aco - gap na literatura.

---

## ðŸŽ¯ Problema de Pesquisa

### QuestÃ£o Principal

**"TabM Ã© efetivo para diagnÃ³stico de doenÃ§a cardÃ­aca em dados tabulares clÃ­nicos?"**

### Contexto

- Modelos baseados em atenÃ§Ã£o (Transformers) sÃ£o populares, mas complexos e computacionalmente custosos (complexidade quadrÃ¡tica).
- **TabM** surge como uma alternativa simples baseada em MLP que supera modelos de atenÃ§Ã£o como FT-Transformer.
- Dataset Cleveland: 297 pacientes (160 saudÃ¡veis, 137 doentes)
- Alguns folds apresentam alta taxa de erro (atÃ© 30%)

### Gap na Literatura

- **Nenhum estudo anterior aplicou TabM em diagnÃ³stico de doenÃ§a cardÃ­aca**
- Falta de benchmarks de arquiteturas modernas de MLP em dados mÃ©dicos tabulares
- Necessidade de validaÃ§Ã£o em contextos clÃ­nicos reais

### Desafios

- Dataset pequeno (297 amostras)
- Desbalanceamento de classes (54% vs 46%)
- Variabilidade entre folds - alguns com distribuiÃ§Ã£o atÃ­pica
- Necessidade de capturar relaÃ§Ãµes complexas entre features clÃ­nicas de forma eficiente

### HipÃ³teses (Benchmarking Descritivo)

**H1 (HipÃ³tese Alternativa)**:
TabM Ã© viÃ¡vel para diagnÃ³stico de doenÃ§a cardÃ­aca no dataset Cleveland, demonstrando desempenho competitivo com o estado da arte reportado na literatura, alcanÃ§ando:

- **AcurÃ¡cia** dentro da faixa esperada
- **F1-Score** competitivo
- **AUC-ROC** comparÃ¡vel
- **Precision** adequada para contexto clÃ­nico
- **Recall** elevado para minimizar falsos negativos

**H0 (HipÃ³tese Nula)**:
TabM nÃ£o alcanÃ§a desempenho competitivo com o estado da arte em diagnÃ³stico de doenÃ§a cardÃ­aca, apresentando resultados significativamente inferiores em mÃºltiplas mÃ©tricas.

---

## SoluÃ§Ã£o Proposta

### 0. Feature Selection

SeleÃ§Ã£o cuidadosa de features clÃ­nicas relevantes:

- **1 Feature NumÃ©rica**: `oldpeak` (ST depression induzida por exercÃ­cio)
- **5 Features CategÃ³ricas**: `cp`, `exang`, `slope`, `ca`, `thal`
- **ReduÃ§Ã£o**: De 13 para 6 features (54% reduÃ§Ã£o)
- **BenefÃ­cio**: Reduz ruÃ­do, melhora interpretabilidade, acelera treinamento

### 1. Arquitetura TabM

TabM Ã© descrita pelos autores como **"a simple feed-forward MLP-based model"** que combina a simplicidade de MLPs com a eficiÃªncia de ensembles.

**Principais CaracterÃ­sticas**:

- **MLP Simples**: Baseado em redes neurais feedforward tradicionais, evitando a complexidade quadrÃ¡tica dos Transformers.
- **BatchEnsemble**: TÃ©cnica que permite treinar mÃºltiplos "membros" do ensemble simultaneamente de forma eficiente.
- **PiecewiseLinearEmbeddings**: TÃ©cnica de embedding para features numÃ©ricas.

**Por que TabM?**

1.  **Supera modelos com atenÃ§Ã£o**: "MLP coupled with BatchEnsemble [...] right away outperforms popular attention-based models, such as FT-Transformer".
2.  **EficiÃªncia Computacional**: "Compared to attention-based models, TabM does not suffer from quadratic computational complexity".
3.  **Simplicidade**: Arquitetura feedforward direta, fÃ¡cil de implementar e ajustar.

**HiperparÃ¢metros Chave**:

- `n_blocks`: NÃºmero de camadas/blocos residuais.
- `d_block`: Largura da camada (neurÃ´nios).
- `d_embedding`: Dimensionalidade dos embeddings.
- `dropout`: RegularizaÃ§Ã£o.

### 2. SMOTE HÃ­brido (TÃ©cnica Complementar)

ImplementaÃ§Ã£o que trata dados numÃ©ricos e categÃ³ricos para balanceamento:

**Features NumÃ©ricas**: InterpolaÃ§Ã£o linear entre vizinhos prÃ³ximos
**Features CategÃ³ricas**: SeleÃ§Ã£o aleatÃ³ria

**ParÃ¢metro Otimizado**: `smote_sampling_strategy` (0.86-1.0)

### 3. OtimizaÃ§Ã£o com Optuna

- 100 trials para encontrar melhores hiperparÃ¢metros
- ValidaÃ§Ã£o cruzada interna (3 folds)
- CritÃ©rio: Maximizar AUC-ROC

### 4. ValidaÃ§Ã£o Rigorosa

- 10-Fold Stratified Cross-Validation
- SMOTE aplicado apenas no conjunto de treinamento
- ValidaÃ§Ã£o em dados originais (sem SMOTE)
- Threshold otimizado por fold (Youden's J)

---

## ðŸ“Š Dataset: Cleveland Heart Disease

### CaracterÃ­sticas

- **Fonte**: UCI Machine Learning Repository
- **InstÃ¢ncias**: 303 originais â†’ 297 apÃ³s limpeza
- **Features**: 13 atributos clÃ­nicos
- **Target**: DiagnÃ³stico de doenÃ§a coronariana (binÃ¡rio)

### Features Selecionadas

| Tipo        | Features                                                                                                  |
| ----------- | --------------------------------------------------------------------------------------------------------- |
| NumÃ©ricas   | `oldpeak` (ST depression induzida por exercÃ­cio)                                                          |
| CategÃ³ricas | `cp` (tipo de dor), `exang` (angina induzida), `slope` (inclinaÃ§Ã£o ST), `ca` (vasos), `thal` (talassemia) |

### DistribuiÃ§Ã£o de Classes

```
Classe 0 (SaudÃ¡veis):  160 (54%)
Classe 1 (Doentes):    137 (46%)
RazÃ£o:                 1.17:1
```

### Arquitetura do Modelo

```
Input (1 numÃ©rica + 5 categÃ³ricas)
    â†“
PiecewiseLinearEmbeddings (features numÃ©ricas)
    â†“
TabM Blocks (MLP + BatchEnsemble)
    â†“
Camadas Densas (Feed-Forward)
    â†“
Dropout (regularizaÃ§Ã£o)
    â†“
Output (probabilidade de doenÃ§a - Ensemble Mean)
```

### HiperparÃ¢metros Otimizados (Optuna)

```json
{
  "n_blocks": 2,
  "d_block": 384,
  "lr": 0.00401,
  "weight_decay": 0.00309,
  "dropout": 0.0698,
  "d_embedding": 28,
  "n_bins": 17,
  "smote_sampling_strategy": 0.906,
  "use_embeddings": true,
  "use_smote": true
}
```

### Processo de OtimizaÃ§Ã£o

1. **Optuna**: 100 trials com 3-fold CV interna
2. **CritÃ©rio**: Maximizar AUC-ROC
3. **Pruning**: Early stopping se performance nÃ£o melhora
4. **Tempo**: ~30-60 minutos

### ValidaÃ§Ã£o Final

1. **10-Fold Stratified Cross-Validation**
2. **SMOTE** aplicado em cada fold (balanceamento)
3. **Threshold otimizado** por fold (Youden's J)
4. **MÃ©tricas**: AUC-ROC, Accuracy, Precision, Recall, F1-score

---

## ðŸ“ˆ Resultados

### SMOTE - Teste

```
>>> TESTE DE SMOTE <<<
Usando sampling_strategy=1.0 (balanceamento perfeito)
SMOTE: Gerando 23 amostras sintÃ©ticas
  Classe minoritÃ¡ria: 1 (137 amostras)
  Classe majoritÃ¡ria: 0 (160 amostras)
  Dataset original: 297 amostras
  Dataset com SMOTE: 320 amostras
  Nova distribuiÃ§Ã£o: [160 160]
```

### OtimizaÃ§Ã£o com Optuna

- **Melhor AUC-ROC**: ~0.85 (validaÃ§Ã£o interna)
- **Trials completados**: 100
- **Melhor sampling_strategy**: 0.894

### Impacto Esperado em Folds ProblemÃ¡ticos

| Fold | Antes      | Depois       | Melhoria |
| ---- | ---------- | ------------ | -------- |
| 6    | 30.0% erro | ~12-15% erro | -50-60%  |
| 4    | 16.7% erro | ~8-10% erro  | -40-50%  |
| 5    | 16.7% erro | ~8-10% erro  | -40-50%  |
| 7    | 16.7% erro | ~8-10% erro  | -40-50%  |

---

## ðŸ“ QuestÃµes de Pesquisa

### QuestÃ£o Principal

**"Qual Ã© o desempenho de TabM em diagnÃ³stico de doenÃ§a cardÃ­aca no dataset Cleveland e como se compara com o estado da arte reportado na literatura?"**

### QuestÃµes SecundÃ¡rias

1. **"TabM alcanÃ§a mÃ©tricas competitivas com a literatura?"**

   - MÃ©tricas: AcurÃ¡cia, F1-Score, AUC-ROC, Precision, Recall
   - AnÃ¡lise: ComparaÃ§Ã£o com benchmarks da literatura

2. **"TabM generaliza bem em folds com diferentes distribuiÃ§Ãµes de dados?"**

   - MÃ©trica: Desvio padrÃ£o e variÃ¢ncia de performance entre folds
   - AnÃ¡lise: Robustez em folds problemÃ¡ticos vs normais

3. **"Qual Ã© o impacto de SMOTE na performance de TabM em dados desbalanceados?"**

   - AnÃ¡lise: Performance com/sem SMOTE
   - MÃ©tricas: Recall (minimizar falsos negativos), Precision

4. **"O TabM com BatchEnsemble supera modelos de Ã¡rvore de decisÃ£o (XGBoost/RandomForest)?"**
   - AnÃ¡lise: ComparaÃ§Ã£o de mÃ©tricas
   - MÃ©trica: AcurÃ¡cia e AUC-ROC comparativa

---

## ï¿½ Interface Web (Streamlit)

Este projeto inclui uma interface web interativa para realizar diagnÃ³sticos em tempo real usando o modelo treinado.

### Como Rodar

1. **Instale as dependÃªncias**:

   ```bash
   pip install streamlit
   ```

2. **Execute o aplicativo**:

   ```bash
   streamlit run app.py
   ```

3. **Acesse no navegador**:
   - Local: `http://localhost:8501`
   - Network: EndereÃ§o IP mostrado no terminal

### Funcionalidades

- **Input Interativo**: FormulÃ¡rio para inserir dados do paciente (Oldpeak, Dor no peito, etc.)
- **DiagnÃ³stico em Tempo Real**: CÃ¡lculo de probabilidade de doenÃ§a cardÃ­aca
- **InterpretaÃ§Ã£o**: NÃ­veis de risco (Baixo, Moderado, Alto) e recomendaÃ§Ãµes
- **VisualizaÃ§Ã£o**: Barra de progresso de risco

---

## ï¿½ðŸ”§ Como Executar

### PrÃ©-requisitos

```bash
pip install tabm rtdl_num_embeddings optuna scikit-learn torch pandas numpy matplotlib
```

### ExecuÃ§Ã£o Passo a Passo

#### 1. CÃ©lula 1-4: Setup e Carregamento

```python
# InstalaÃ§Ã£o, imports, carregamento de dados, seleÃ§Ã£o de features
# Tempo: ~30 segundos
```

#### 2. CÃ©lula 5: Teste de SMOTE

```python
# Verifica funcionamento de SMOTE com sampling_strategy=1.0
# Tempo: ~5 segundos
# Esperado: 23 amostras sintÃ©ticas geradas
```

#### 3. CÃ©lula 7: OtimizaÃ§Ã£o com Optuna

```python
# Busca melhores hiperparÃ¢metros (100 trials)
# Tempo: 30-60 minutos
# Salva em: best_params_tabm.json
```

#### 4. CÃ©lula 8: Experimento Final

```python
# 10-fold CV com melhores parÃ¢metros
# Tempo: 20-40 minutos
# Gera grÃ¡fico ROC com intervalo de confianÃ§a
```

#### 5. CÃ©lula 9: AnÃ¡lise de Features

```python
# Incerteza e importÃ¢ncia de features
# Tempo: ~5 minutos
```

---

## ðŸ“ Estrutura de Arquivos

```
TabM/
â”œâ”€â”€ tabm.ipynb                          # Notebook principal
â”œâ”€â”€ best_params_tabm.json               # HiperparÃ¢metros otimizados
â”œâ”€â”€ README.md                           # Este arquivo
â”œâ”€â”€ SMOTE_IMPLEMENTATION.md             # Detalhes tÃ©cnicos de SMOTE
â”œâ”€â”€ SMOTE_LITERATURE_REVIEW.md          # RevisÃ£o de literatura
â””â”€â”€ CHANGES_SUMMARY.md                  # Resumo de mudanÃ§as
```

---

## ðŸ” AnÃ¡lise Detalhada de Folds

### Fold 6 (Mais ProblemÃ¡tico)

```
Tamanho: 30 amostras
Classe 0: 16 (53.3%)
Classe 1: 14 (46.7%)
Erros: 9/30 (30.0%)
PadrÃ£o: 6 Falsos Negativos, 3 Falsos Positivos

CaracterÃ­sticas de erro:
- oldpeak: mÃ©dia=-0.073 (ligeiramente abaixo da mÃ©dia)
- cp: distribuiÃ§Ã£o desbalanceada (2 tipo 0, 14 tipo 3)
- thal: distribuiÃ§Ã£o desbalanceada (15 tipo 0, 14 tipo 2)
```

### Fold 4

```
Tamanho: 30 amostras
Classe 0: 16 (53.3%)
Classe 1: 14 (46.7%)
Erros: 5/30 (16.7%)
PadrÃ£o: 2 Falsos Negativos, 3 Falsos Positivos

CaracterÃ­sticas:
- ca: distribuiÃ§Ã£o muito concentrada (23 tipo 0)
- slope: distribuiÃ§Ã£o desbalanceada (18 tipo 0)
```

---

## ðŸŽ“ ContribuiÃ§Ãµes TÃ©cnicas

### 1. Primeira AplicaÃ§Ã£o de TabM em DiagnÃ³stico CardÃ­aco

- **Gap na Literatura**: Nenhum estudo anterior aplicou TabM em contexto de doenÃ§a cardÃ­aca
- Benchmarking de TabM contra estado da arte reportado na literatura
- ValidaÃ§Ã£o rigorosa com 10-fold stratified cross-validation
- Mapeamento de desempenho para futuros pesquisadores

### 2. AvaliaÃ§Ã£o com MÃºltiplas MÃ©tricas

- AnÃ¡lise abrangente: AcurÃ¡cia, F1-Score, AUC-ROC, Precision, Recall
- Foco em Recall para minimizar falsos negativos (crÃ­tico em diagnÃ³stico mÃ©dico)
- ComparaÃ§Ã£o com estado da arte usando mÃºltiplas mÃ©tricas

### 3. SMOTE HÃ­brido para Dados Mistos

- ImplementaÃ§Ã£o que trata numÃ©ricos e categÃ³ricos simultaneamente
- KNN para encontrar vizinhos representativos
- InterpolaÃ§Ã£o inteligente para features numÃ©ricas

### 4. OtimizaÃ§Ã£o Integrada de TabM + SMOTE

- OtimizaÃ§Ã£o conjunta de hiperparÃ¢metros via Optuna
- SMOTE aplicado em cada fold (nÃ£o apenas no dataset completo)
- Melhora robustez em datasets pequenos e desbalanceados

### 5. AnÃ¡lise de GeneralizaÃ§Ã£o em Folds ProblemÃ¡ticos

- IdentificaÃ§Ã£o e anÃ¡lise detalhada de folds com alta taxa de erro
- AvaliaÃ§Ã£o de robustez em diferentes distribuiÃ§Ãµes de dados
- Insights sobre comportamento de TabM em dados heterogÃªneos

---

## ðŸ“š ReferÃªncias BibliogrÃ¡ficas

### SMOTE

1. **Chawla et al., 2002** - "SMOTE: Synthetic Minority Over-sampling Technique"

   - TÃ©cnica original de oversampling

2. **Sowjanya & Mrudula, 2021** - "Effective treatment of imbalanced datasets in health care using modified SMOTE"

   - D-SMOTE e BP-SMOTE para dados mÃ©dicos
   - Resultado: +3% em acurÃ¡cia

3. **El-Sofany et al., 2024** - "A proposed technique for predicting heart disease using machine learning algorithms"
   - SMOTE + SHAP para diagnÃ³stico de doenÃ§a cardÃ­aca
   - Dataset: Cleveland Heart Disease

### TabM

1. **Gorishniy et al., 2024** - "TabM: Advancing Tabular Deep Learning With Parameter-Efficient Ensembling" (ICLR 2025)
   - https://arxiv.org/abs/2410.24210
   - Transformer para dados tabulares com ensemble parameter-efficient
   - Embeddings numÃ©ricos (PiecewiseLinearEmbeddings)
   - Multi-head attention para capturar relaÃ§Ãµes entre features
   - Ensemble de k modelos independentes para robustez

### Heart Disease Dataset

1. **Detrano et al., 1989** - "International application of a new probability algorithm for the diagnosis of coronary artery disease"
   - Dataset original Cleveland
   - 303 pacientes, 76 atributos

---

## ðŸ” AnÃ¡lise Detalhada de Folds

### Fold 6 (Mais ProblemÃ¡tico)

```
Tamanho: 30 amostras
Classe 0: 16 (53.3%)
Classe 1: 14 (46.7%)
Erros: 9/30 (30.0%)
PadrÃ£o: 6 Falsos Negativos, 3 Falsos Positivos

CaracterÃ­sticas de erro:
- oldpeak: mÃ©dia=-0.073 (ligeiramente abaixo da mÃ©dia)
- cp: distribuiÃ§Ã£o desbalanceada (2 tipo 0, 14 tipo 3)
- thal: distribuiÃ§Ã£o desbalanceada (15 tipo 0, 14 tipo 2)
```

### Fold 4

```
Tamanho: 30 amostras
Classe 0: 16 (53.3%)
Classe 1: 14 (46.7%)
Erros: 5/30 (16.7%)
PadrÃ£o: 2 Falsos Negativos, 3 Falsos Positivos

CaracterÃ­sticas:
- ca: distribuiÃ§Ã£o muito concentrada (23 tipo 0)
- slope: distribuiÃ§Ã£o desbalanceada (18 tipo 0)
```

1. **Variantes de SMOTE**: Implementar D-SMOTE e BP-SMOTE
2. **Ensemble**: Combinar TabM com XGBoost e Random Forest
3. **Feature Engineering**: Adicionar interaÃ§Ãµes entre features
4. **Explicabilidade**: Integrar SHAP para interpretabilidade
5. **ValidaÃ§Ã£o Externa**: Testar em datasets adicionais (Framingham, Hungarian)

### Pesquisa Adicional

1. Analisar impacto de diferentes `k_neighbors` em SMOTE
2. Comparar com undersampling e hybrid sampling
3. Estudar efeito de SMOTE em diferentes tamanhos de dataset
4. Investigar borderline-SMOTE para casos ambÃ­guos

---

## ðŸ“ Notas Importantes

### LimitaÃ§Ãµes

- Dataset pequeno (297 amostras)
- Features limitadas (1 numÃ©rica, 5 categÃ³ricas)
- ValidaÃ§Ã£o apenas em dados Cleveland
- Sem validaÃ§Ã£o externa em outros datasets

### ConsideraÃ§Ãµes MÃ©dicas

- Falso Negativo Ã© mais crÃ­tico que Falso Positivo
- SMOTE melhora recall (reduz FN)
- Threshold otimizado por fold pode variar clinicamente
- NecessÃ¡rio validaÃ§Ã£o clÃ­nica antes de deployment

### Reprodutibilidade

- Seed fixo: `RANDOM_STATE = 42`
- Seed diferente por fold: `RANDOM_STATE + fold`
- Todos os hiperparÃ¢metros salvos em `best_params_tabm.json`
- CÃ³digo totalmente determinÃ­stico

---

## ðŸ“ž Contato e DÃºvidas

Para dÃºvidas sobre implementaÃ§Ã£o, resultados ou metodologia, consulte:

- DocumentaÃ§Ã£o tÃ©cnica: `SMOTE_IMPLEMENTATION.md`
- RevisÃ£o de literatura: `SMOTE_LITERATURE_REVIEW.md`
- Resumo de mudanÃ§as: `CHANGES_SUMMARY.md`

---

**Ãšltima atualizaÃ§Ã£o**: Dezembro 2025
**Status**: Experimento em progresso
**VersÃ£o**: 1.0
